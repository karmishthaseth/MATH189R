{\rtf1\ansi\ansicpg1252\cocoartf2511
\cocoatextscaling0\cocoaplatform0{\fonttbl\f0\fswiss\fcharset0 Helvetica;}
{\colortbl;\red255\green255\blue255;}
{\*\expandedcolortbl;;}
\paperw11900\paperh16840\margl1440\margr1440\vieww10800\viewh8400\viewkind0
\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\pardirnatural\partightenfactor0

\f0\fs24 \cf0 \\documentclass\{article\}\
\\usepackage[utf8]\{inputenc\}\
\\usepackage\{amsmath\}\
\\usepackage\{textgreek\}\
\\linespread\{1.5\}\
\\usepackage\{amssymb\}\
\
\{\\Huge \\title\{\\huge Home Work 2\}\}\
\\author\{\\large Karmishtha Seth \}\
\\date\{\\large 12 June 2020\}\
\
\\begin\{document\}\
\
\\maketitle\
\
\{\\huge 1.\}\
\\bigbreak   \
\{\\large a.\}\
\{\\large Let $\\sigma = \\frac\{1\}\{1 + e^\{-x\}\}$\}\
\\bigbreak\
\{\\large then to show: $\\sigma^\{'\}(x) = \\sigma(x)[1 - \\sigma(x])$\}\
\\bigbreak\
\{\\large $\\sigma^\{'\}(x) = \\frac\{d\}\{dx\} (\\frac\{1\}\{1 + e^\{-x\}\}) = \\frac\{d\}\{dx\}((1 + e^\{-x\})^\{-1\})$\}\
\\bigbreak\
\{\\large $= e^\{-x\}(1 + e^\{-x\})^\{-1\} = (\\frac\{1\}\{1 + e^\{-x\}\})(\\frac\{e^\{-x\}\}\{1 + e^\{-x\}\})= \\sigma(x)(\\frac\{1 + e^\{-x\} - 1\}\{1 + e^\{-x\}\})$\}\
\\bigbreak\
\{\\large $= \\sigma(x)(1 - \\frac\{1\}\{1 + e^\{-x\}\}) = \\sigma(x)[1 - \\sigma(x)]$\}\
\\bigbreak\
\{\\large b.\}\
\\bigbreak\
\{\\large negative log likelihood equation for logistic regression =  $\\emph\{nll\}(\\theta)$\}\
\\bigbreak\
\{\\large $\\emph\{nll\}(\\theta) = -$$\\sum_\{i\}y_i log \\sigma(\\theta^\{T\}x_i) + (1 - y_i)log(1 -\\sigma(\\theta^\{T\}x_i))$\}\
\
\\bigbreak\
\{\\large Taking the gradients wrt $\\theta$, we get:\}\
\\bigbreak\
\{\\large $\\nabla_\{\\theta\}\\emph\{nll\}(\\theta) = -$$\\sum_\{i\}y_i \\frac\{1\}\{\\sigma(\\theta^\{T\}x_\{i\})\}\\sigma^\{'\}(\\theta^\{T\}x_\{i\})+(1-y_i)\\frac\{1\}\{1-\\sigma(\\theta^\{T\}x_\{i\})\}(-\\sigma^\{'\}(\\theta^\{T\}x_\{i\}))$\}\
\
\\bigbreak\
\{\\large this can be further simplified to yield\}\
\\bigbreak\
\{\\large $\\nabla_\{\\theta\}\\emph\{nll\}(\\theta)=$$\\sum_\{i\}(\\sigma(\\theta^\{T\}x_\{i\})-y_i)x_i$\}\
\
\{\\large $= \\sum_\{i\}(\\mu_\{i\} - y_i)x_i$\}\
\{\\large $= X^T(\\mu -y)$\}\
\\bigbreak\
\{\\large where $\\mu_i = (\\sigma^\{'\}(\\theta^\{T\}x_\{i\}))$ and $x_\{i\}$ is the ith column of $X^\{T\}$\}\
\\bigbreak\
\{\\large c.\}\
\\bigbreak\
\{\\large Thus, from (b) we can find the Hessian Matrix:\}\
\\bigbreak\
\{\\large So \{H_\{\\theta\}\} =\\nabla_\{\\theta\}(\\nabla_\{\\theta\}\\emph\{nll\}(\\theta))^\{T\} = \\nabla_\{\\theta\}[X^\{T\}(\\mu - y)]^\{T\} = \\nabla_\{\\theta\}(\\mu^\{T\}X - y^\{T\}X)\}\
\\bigbreak\
\{\\large = $\\nabla_\{\\theta\}\\mu^\{T\}X = \\nabla_\{\\theta\}\\sigma(X\\theta)^\{T\}X$ = $X^\{T\}diag(\\mu(1-\\mu))X = X^\{T\}SX$\}\
\\bigbreak\
\{\\large where S is $\\mu(1-\\mu)$. Therefore we can see that $\{H_\{\\theta\}\}$ is positive and semi-definite and from the equivalence above and assuming eigenvalues of S >0, we can also say that S is positive and semi-definite. Since S is a diagonal matrix, its eigenvalues are the entries on the diagonal, Hence:\}\
\\bigbreak\
\{\\large $\\mu_\{i\}(1-\\mu_\{i\}) = \\sigma(\\theta^\{T\}x_i)(1 - \\sigma(\\theta^\{T\}x_\{i\})) \\geq 0$\}\
\{\\large and since 0<$\\sigma(.)$<1, we need $\\sigma(.)(1-\\sigma(.)) \\geq 0$ and thus we can show that the hessian matrix H is positive semi definite\}\
\\bigbreak\
\{\\huge 2.\}\
\\bigbreak\
\{\\large $$\\int_\{\\rm I\\!R\}\\frac\{1\}\{Z\}exp(\\frac\{-x^2\}\{2\\sigma^2\})dx = 1$$\}\
\\bigbreak\
\{\\large $$\\int_\{\\rm I\\!R\}exp(\\frac\{-x^2\}\{2\\sigma^2\})dx = Z$$\}\
\\bigbreak\
\{\\large $$Z^2 = \\int_\{\\rm I\\!R\}exp(\\frac\{-x^2\}\{2\\sigma^2\})dx\\int_\{\\rm I\\!R\}exp(\\frac\{-y^2\}\{2\\sigma^2\})dy = \\iint_\{\\rm I\\!R^2\}exp(-\\frac\{x^\{2\}+y^\{2\}\}\{2\\sigma^2\})\\,dx\\,dy$$\}\
\\bigbreak\
\{\\large $$ = \\int_\{0\}^\{\\infty\}\\int_\{0\}^\{2\\pi\} exp(\\frac\{-r^2\}\{2\\sigma^2\})r\\,d\{\\theta\} \\,dr = 2\{\\pi(\\sigma^2)\}\\int_\{0\}^\{\\infty\} exp(\\frac\{-r^2\}\{2\\sigma^2\})(\\frac\{-2\}\{\\sigma^2\})dr $$\}\
\\bigbreak\
\{\\large on solving, we get $ = -2\\pi\\sigma\{^2\}(0-1) = 2\\pi\\sigma^\{2\}$\}\
\\bigbreak\
\{\\large Hence, we get $Z^2 = 2\\pi\\sigma^\{2\} \\Rightarrow Z = \\surd(2\\pi\\sigma^\{2\}) = \\surd(2\\pi)\\sigma $\}\
\\bigbreak\
\{\\huge 3.\}\
\{\\large refer to pdf\}\
\
\
\\end\{document\}}